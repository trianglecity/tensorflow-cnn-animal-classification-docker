from PIL import Image

from os import listdir
from os.path import isfile, join

import fnmatch
import os
import math
import tensorflow as tf

from tensorflow.python.framework import ops
from tensorflow.python.framework import dtypes

from datetime import datetime
import time
import numpy as np


batch_size = 2
test_size = 3

def init_weights(shape):
    return tf.Variable(tf.random_normal(shape, stddev=0.01))


def model(X, w, w2, w4, w_o, p_keep_conv, p_keep_hidden):
    	l1a = tf.nn.relu(tf.nn.conv2d(X, w,                       # l1a shape=(?, 140, 160, 32)
                        strides=[1, 1, 1, 1], padding='SAME'))
    	l1 = tf.nn.max_pool(l1a, ksize=[1, 2, 2, 1],              # l1 shape=(?, 70, 80, 32)
                        strides=[1, 2, 2, 1], padding='SAME')
    	l1 = tf.nn.dropout(l1, p_keep_conv)
	####

    	l2a = tf.nn.relu(tf.nn.conv2d(l1, w2,                     # l2a shape=(?, 70, 80, 64)
                        strides=[1, 1, 1, 1], padding='SAME'))
    	l2 = tf.nn.max_pool(l2a, ksize=[1, 2, 2, 1],              # l2 shape=(?, 35, 40, 64)
                        strides=[1, 2, 2, 1], padding='SAME')

        l2 = tf.reshape(l2, [-1, w4.get_shape().as_list()[0]]) # reshape to (?, 2048)
    	l2 = tf.nn.dropout(l2, p_keep_conv)

    	
    	
    	l4 = tf.nn.relu(tf.matmul(l2, w4))
    	l4 = tf.nn.dropout(l4, p_keep_hidden)

    	pyx = tf.matmul(l4, w_o)
	return pyx

############

def distorted_inputs( batch_size):

	
	read_input = read_animals()
	
	reshaped_image = tf.cast(read_input.uint8image, tf.float32)

	height = 140
  	width = 160

	print "height = ", height
	print "width = ", width

	## Randomly flip the image horizontally.
  	##distorted_image = tf.image.random_flip_left_right(reshaped_image)

	
	# Set the shapes of tensors.
	print read_input.uint8image
	print reshaped_image
	print read_input.label

	##To use tf.train_batch we need to define the shape of our image tensors before they can be combined into batches.

	## updates the static shape of a Tensor object, 
	## and it is typically used to provide ADDITIONAL shape information when this cannot be inferred directly. 
	## It does NOT change the dynamic shape of the tensor.

  	reshaped_image.set_shape([height, width, 3])

	##
	## batch(
    	##	tensors,
    	##	batch_size,
    	##	num_threads=1,
    	##	capacity=32,
    	##	enqueue_many=False,
    	##	shapes=None,
    	##	dynamic_pad=False,
    	##	allow_smaller_final_batch=False,
    	##	shared_name=None,
    	##	name=None
	## )
	##
  	

	train_image_batch, train_label_batch = tf.train.batch(
                                    [reshaped_image, read_input.label],
                                    batch_size=batch_size,
				    capacity=32	
                                    #,num_threads=1
                                    )

	print "return batch"
	print train_image_batch
	print train_label_batch
	
	return train_image_batch, train_label_batch

def read_animals():

    	
	## class
	class ANIMAL4Record(object):
    		pass

	## scprit for loading images
	
  	result = ANIMAL4Record()	

	
  	result.height = 140
  	result.width  = 160
  	result.depth  = 3
  	
	
	## bear  -- label 0

	images_bear = []
	labels_bear = []

	for root, dirs, filenames in os.walk(top = './animals/bear', topdown=True):
    		for filename in fnmatch.filter(filenames, '*.jpg'):
        		images_bear.append(os.path.join(root, filename))
			labels_bear.append([1, 0, 0, 0])

	## deer -- label 1

	images_deer = []
	labels_deer = []

	for root, dirs, filenames in os.walk(top = './animals/deer', topdown=True):
    		for filename in fnmatch.filter(filenames, '*.jpg'):
        		images_deer.append(os.path.join(root, filename))
			labels_deer.append([0, 1, 0, 0])

	## duck -- label 2

	
	images_duck = []
	labels_duck = []

	for root, dirs, filenames in os.walk(top = './animals/duck', topdown=True):
    		for filename in fnmatch.filter(filenames, '*.jpg'):
        		images_duck.append(os.path.join(root, filename))
			labels_duck.append([0, 0, 1, 0])


	## turtle -- label 3

	images_turtle = []
	labels_turtle = []

	for root, dirs, filenames in os.walk(top = './animals/turtle', topdown=True):
    		for filename in fnmatch.filter(filenames, '*.jpg'):
        		images_turtle.append(os.path.join(root, filename))
			labels_turtle.append([0, 0, 0 ,1])

	labels_total = labels_bear + labels_deer + labels_duck + labels_turtle
	images_total = images_bear + images_deer + images_duck + images_turtle
	
	
	for f in images_total:
    		if not tf.gfile.Exists(f):
      			raise ValueError('Failed to find file: ' + f)	
	
	n_images = len(labels_total)
	print "n_images = ", n_images	

	
	# convert string into tensors
	all_images = ops.convert_to_tensor(images_total, dtype=dtypes.string)
	all_labels = ops.convert_to_tensor(labels_total, dtype=dtypes.int32)
	

	# create input queues

	##
	##	slice_input_producer(
    	##		tensor_list,
    	##		num_epochs=None, 	## produces each slice num_epochs times before generating an OutOfRange error.
    	##		shuffle=True,
    	##		seed=None,
    	##		capacity=32,		## Sets the queue capacity.
    	##		shared_name=None,
    	##		name=None
	##	)
	##

	##	A list of tensors, one for each element of tensor_list
	##
	
	train_input_queue = tf.train.slice_input_producer(
                                    	[all_images, all_labels],
				  	num_epochs=10,
                                    	shuffle=True)

	# process path and string tensor into an image and a label
	file_content = tf.read_file(train_input_queue[0])
	train_image = tf.image.decode_jpeg(file_content, channels=3)
	train_label = train_input_queue[1]


	##result.uint8image = tf.image.decode_jpeg(value_image, channels=3)
	result.uint8image = train_image
	
	# The first bytes represent the label, which we convert from uint8->int32.
        # tf.cast(a, tf.int32) 
	print labels_total
		
	result.label = train_label
           
	result.n_images = 80

 	return result
 	

X = tf.placeholder("float", [None, 140, 160, 3])
Y = tf.placeholder("float", [None, 4])

##trX, trY = distorted_inputs( 1)

w = init_weights([3, 3, 3, 32])       # 3x3x1 conv, 32 outputs
w2 = init_weights([3, 3, 32, 64])     # 3x3x32 conv, 64 outputs

##w3 = init_weights([3, 3, 64, 128]) # 3x3x32 conv, 128 outputs
##33280 but is 92160
## w4 = init_weights([128 * 4 * 4, 625]) # FC 128 * 4 * 4 inputs, 625 outputs

w4 = init_weights([89600, 625]) # FC 13*20*128 inputs, 625 outputs
w_o = init_weights([625, 4])         # FC 625 inputs, 4 outputs (labels)

p_keep_conv = tf.placeholder("float")
p_keep_hidden = tf.placeholder("float")

trX, trY = distorted_inputs( 1)
py_x = model(trX, w, w2, w4, w_o, p_keep_conv, p_keep_hidden)



cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=py_x, labels=trY))
train_op = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)
predict_op = tf.argmax(py_x, 1)

# Launch the graph in a session
with tf.Session() as sess:
    # you need to initialize all variables
    tf.global_variables_initializer().run()

    for i in range(100):
        
             
            sess.run(train_op, feed_dict={p_keep_conv: 0.8, p_keep_hidden: 0.5})

        	


