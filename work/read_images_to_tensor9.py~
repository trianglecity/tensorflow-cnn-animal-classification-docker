
from PIL import Image

from os import listdir
from os.path import isfile, join

import fnmatch
import os
import math
import tensorflow as tf

from tensorflow.python.framework import ops
from tensorflow.python.framework import dtypes

from datetime import datetime
import time

IMAGE_HEIGHT = 140
IMAGE_WIDTH  = 160

NUM_CLASSES = 4

NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 80

NUM_EPOCHS_PER_DECAY = 1.0
INITIAL_LEARNING_RATE = 0.01 
LEARNING_RATE_DECAY_FACTOR = 0.01
MOVING_AVERAGE_DECAY = 0.9999 

FLAGS = tf.app.flags.FLAGS

# Basic model parameters.

tf.app.flags.DEFINE_string('train_dir', '/tmp/animal4_train',
                           """Directory where to write event logs """
                           """and checkpoint.""")
tf.app.flags.DEFINE_integer('max_steps', 200, """Number of batches to run.""")
tf.app.flags.DEFINE_boolean('log_device_placement', False,
                            """Whether to log device placement.""")
tf.app.flags.DEFINE_integer('log_frequency', 1,
                            """How often to log results to the console.""")
tf.app.flags.DEFINE_integer('batch_size', 4, """Number of images to process in a batch.""")

tf.app.flags.DEFINE_string('checkpoint_dir', '/tmp/animal4_train',
                           """Directory where to read model checkpoints.""")
tf.app.flags.DEFINE_integer('num_examples', 80,
                            """Number of examples to run.""")

def read_animals():


	## class
	class ANIMAL4Record(object):
    		pass

	## scprit for loading images
	
  	result = ANIMAL4Record()	

	
  	result.height = IMAGE_HEIGHT
  	result.width  = IMAGE_WIDTH
  	result.depth  = 3
  	
	
	## bear  -- label 0

	images_bear = []
	labels_bear = []

	for root, dirs, filenames in os.walk(top = './animals/bear', topdown=True):
    		for filename in fnmatch.filter(filenames, '*.jpg'):
        		images_bear.append(os.path.join(root, filename))
			labels_bear.append(0)

	## deer -- label 1

	images_deer = []
	labels_deer = []

	for root, dirs, filenames in os.walk(top = './animals/deer', topdown=True):
    		for filename in fnmatch.filter(filenames, '*.jpg'):
        		images_deer.append(os.path.join(root, filename))
			labels_deer.append(1)

	## duck -- label 2

	
	images_duck = []
	labels_duck = []

	for root, dirs, filenames in os.walk(top = './animals/duck', topdown=True):
    		for filename in fnmatch.filter(filenames, '*.jpg'):
        		images_duck.append(os.path.join(root, filename))
			labels_duck.append(2)


	## turtle -- label 3

	images_turtle = []
	labels_turtle = []

	for root, dirs, filenames in os.walk(top = './animals/turtle', topdown=True):
    		for filename in fnmatch.filter(filenames, '*.jpg'):
        		images_turtle.append(os.path.join(root, filename))
			labels_turtle.append(3)

	labels_total = labels_bear + labels_deer + labels_duck + labels_turtle
	images_total = images_bear + images_deer + images_duck + images_turtle
	
	
	for f in images_total:
    		if not tf.gfile.Exists(f):
      			raise ValueError('Failed to find file: ' + f)	
	
	n_images = len(labels_total)
	print "n_images = ", n_images	

	
	# convert string into tensors
	all_images = ops.convert_to_tensor(images_total, dtype=dtypes.string)
	all_labels = ops.convert_to_tensor(labels_total, dtype=dtypes.int32)
	

	# create input queues

	##
	##	slice_input_producer(
    	##		tensor_list,
    	##		num_epochs=None, 	## produces each slice num_epochs times before generating an OutOfRange error.
    	##		shuffle=True,
    	##		seed=None,
    	##		capacity=32,		## Sets the queue capacity.
    	##		shared_name=None,
    	##		name=None
	##	)
	##

	##	A list of tensors, one for each element of tensor_list
	##
	
	train_input_queue = tf.train.slice_input_producer(
                                    	[all_images, all_labels],
				  	num_epochs=10,
                                    	shuffle=True)

	# process path and string tensor into an image and a label
	file_content = tf.read_file(train_input_queue[0])
	train_image = tf.image.decode_jpeg(file_content, channels=3)
	train_label = train_input_queue[1]


	##result.uint8image = tf.image.decode_jpeg(value_image, channels=3)
	result.uint8image = train_image
	
	# The first bytes represent the label, which we convert from uint8->int32.
        # tf.cast(a, tf.int32) 
	print labels_total
		
	result.label = train_label
           
	result.n_images = 80

 	return result
 	
###
###

def distorted_inputs( batch_size):

	
	read_input = read_animals()
	
	reshaped_image = tf.cast(read_input.uint8image, tf.float32)

	height = IMAGE_HEIGHT
  	width = IMAGE_WIDTH

	print "height = ", height
	print "width = ", width

	## Randomly flip the image horizontally.
  	distorted_image = tf.image.random_flip_left_right(reshaped_image)

	
	# Set the shapes of tensors.
	print read_input.uint8image
	print distorted_image
	print read_input.label

	##To use tf.train_batch we need to define the shape of our image tensors before they can be combined into batches.

	## updates the static shape of a Tensor object, 
	## and it is typically used to provide ADDITIONAL shape information when this cannot be inferred directly. 
	## It does NOT change the dynamic shape of the tensor.

  	distorted_image.set_shape([height, width, 3])

	##
	## batch(
    	##	tensors,
    	##	batch_size,
    	##	num_threads=1,
    	##	capacity=32,
    	##	enqueue_many=False,
    	##	shapes=None,
    	##	dynamic_pad=False,
    	##	allow_smaller_final_batch=False,
    	##	shared_name=None,
    	##	name=None
	## )
	##
  	

	train_image_batch, train_label_batch = tf.train.batch(
                                    [distorted_image, read_input.label],
                                    batch_size=batch_size,
				    capacity=32	
                                    #,num_threads=1
                                    )

	print "return batch"
	print train_image_batch
	print train_label_batch
	
	return train_image_batch, train_label_batch


##########
def inference(features):
	
	print "in inference"

	## creates a new tensor with a different dynamic shape
	images = tf.reshape(features, [-1, IMAGE_HEIGHT, IMAGE_WIDTH, 3])
	
	# conv1
  	with tf.variable_scope('conv1') as scope:
    		kernel = _variable_with_weight_decay('weights',
                                         shape=[3, 3, 3, 64],
                                         stddev=5e-2,
                                         wd=0.0)
    		conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')
    		biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.0))
    		pre_activation = tf.nn.bias_add(conv, biases)
    		conv1 = tf.nn.relu(pre_activation, name=scope.name)


  	# pool1
  	pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],
                         	padding='SAME', name='pool1')

	# norm1
  	norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,   		name='norm1')
	
	
	# conv2
  	with tf.variable_scope('conv2') as scope:
    		kernel = _variable_with_weight_decay('weights',
                                         shape=[3, 3, 64, 64],
                                         stddev=5e-2,
                                         wd=0.0)
    		conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding='SAME')
    		biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))
    		pre_activation = tf.nn.bias_add(conv, biases)
    		conv2 = tf.nn.relu(pre_activation, name=scope.name)


  	# norm2
  	norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm2')
  	# pool2
  	pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1],
                         strides=[1, 2, 2, 1], padding='SAME', name='pool2')

	# local3
  	with tf.variable_scope('local3') as scope:
    		# Move everything into depth so we can perform a single matrix multiply.
    		reshape = tf.reshape(pool2, [FLAGS.batch_size, -1])
    		dim = reshape.get_shape()[1].value
    		weights = _variable_with_weight_decay('weights', shape=[dim, 1024],
                                          stddev=0.04, wd=0.004)
    		biases = _variable_on_cpu('biases', [1024], tf.constant_initializer(0.1))
    		local3 = tf.nn.relu(tf.matmul(reshape, weights) + biases, name=scope.name)

	# local4
  	with tf.variable_scope('local4') as scope:
    		weights = _variable_with_weight_decay('weights', shape=[1024, 256],
                                          stddev=0.04, wd=0.004)
    		biases = _variable_on_cpu('biases', [256], tf.constant_initializer(0.1))
    		local4 = tf.nn.relu(tf.matmul(local3, weights) + biases, name=scope.name)

	with tf.variable_scope('softmax_linear') as scope:
    		weights = _variable_with_weight_decay('weights', [256, NUM_CLASSES],
                                          stddev=1/256.0, wd=0.0)
    		biases = _variable_on_cpu('biases', [NUM_CLASSES],
                              tf.constant_initializer(0.0))
    		softmax_linear = tf.add(tf.matmul(local4, weights), biases, name=scope.name)

	
	return softmax_linear

def estimate_loss(logits, labels):

	print "in estimate_loss"
	# Calculate the average cross entropy loss across the batch.
  	labels = tf.cast(labels, tf.int64)

	## sparse_softmax_cross_entropy_with_logits(
   	## 						_sentinel=None,
    	##						labels=None,
    	##						logits=None,
    	##						name=None
	##					)


  	cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(
      		labels=labels, logits=logits, name='cross_entropy_per_example')
  	cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')
  	tf.add_to_collection('losses', cross_entropy_mean)

  	# The total loss is defined as the cross entropy loss plus all of the weight
  	# decay terms (L2 loss).
  	return tf.add_n(tf.get_collection('losses'), name='total_loss')

	

def _variable_on_cpu(name, shape, initializer):
 
  with tf.device('/cpu:0'):
    	dtype = tf.float32
    	var = tf.get_variable(name, shape, initializer=initializer, dtype=dtype)

  return var



def _variable_with_weight_decay(name, shape, stddev, wd):
  
  dtype =  tf.float32
  var = _variable_on_cpu(
      name,
      shape,
      tf.truncated_normal_initializer(stddev=stddev, dtype=dtype))
  if wd is not None:
    weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name='weight_loss')
    tf.add_to_collection('losses', weight_decay)
  return var
  


def _add_loss_summaries(total_loss):
  
  # Compute the moving average of all individual losses and the total loss.
  loss_averages = tf.train.ExponentialMovingAverage(0.9, name='avg')
  losses = tf.get_collection('losses')
  loss_averages_op = loss_averages.apply(losses + [total_loss])

  
  return loss_averages_op

def get_train_op(total_loss, global_step):
	print "in get_train_op"

	# Variables that affect learning rate.
  	num_batches_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN / FLAGS.batch_size
  	decay_steps = int(num_batches_per_epoch * NUM_EPOCHS_PER_DECAY)

	
	# Decay the learning rate exponentially based on the number of steps.
  	lr = tf.train.exponential_decay(INITIAL_LEARNING_RATE,
                                  	global_step,
                                  	decay_steps,
                                  	LEARNING_RATE_DECAY_FACTOR,
                                  	staircase=True)
	
	# Generate moving averages of all losses and associated summaries.
  	loss_averages_op = _add_loss_summaries(total_loss)

	# Compute gradients.
  	with tf.control_dependencies([loss_averages_op]):
    		opt = tf.train.GradientDescentOptimizer(lr)
    		grads = opt.compute_gradients(total_loss)

	# Apply gradients.
  	apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)

	# Track the moving averages of all trainable variables.
  	variable_averages = tf.train.ExponentialMovingAverage(
      			MOVING_AVERAGE_DECAY, global_step)
  	variables_averages_op = variable_averages.apply(tf.trainable_variables())

  	with tf.control_dependencies([apply_gradient_op, variables_averages_op]):
    		train_op = tf.no_op(name='train')
	
	
	return train_op

	

def train():

	print "in train"
	global_step = tf.contrib.framework.get_or_create_global_step()
	
	print "batch_size = ", FLAGS.batch_size
	images, labels = distorted_inputs( batch_size = FLAGS.batch_size)
	
	logits = inference(images)
	
	loss = estimate_loss(logits, labels)
	
	predictions = {
    		"classes": tf.argmax( input=logits, axis=1),
    		"probabilities": tf.nn.softmax( logits, name="softmax_tensor")
	}
	
	
	
	train_op = get_train_op(loss, global_step)

	class _LoggerHook(tf.train.SessionRunHook):
      		"""Logs loss and runtime."""

      		def begin(self):
        		self._step = -1
        		self._start_time = time.time()

      		def before_run(self, run_context):
        		self._step += 1
        		return tf.train.SessionRunArgs(loss)  # Asks for loss value.

      		def after_run(self, run_context, run_values):
        		if self._step % FLAGS.log_frequency == 0:
          			current_time = time.time()
          			duration = current_time - self._start_time
          			self._start_time = current_time

          			loss_value = run_values.results
          			examples_per_sec = FLAGS.log_frequency * FLAGS.batch_size / duration
          			sec_per_batch = float(duration / FLAGS.log_frequency)

          			format_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f ' 'sec/batch)')
          			print (format_str % (datetime.now(), self._step, loss_value, examples_per_sec, sec_per_batch))


	##
	##	MonitoredTrainingSession(
    	##		master='',
    	##		is_chief=True,
    	##		checkpoint_dir=None,
    	##		scaffold=None,
    	##		hooks=None,
    	##		chief_only_hooks=None,
    	##		save_checkpoint_secs=600,
    	##		save_summaries_steps=100,
    	##		save_summaries_secs=None,
    	##		config=None,
    	##		stop_grace_period_secs=120
	##	)
	##
	##
	
	

	batch_counter = 0
	with tf.train.MonitoredTrainingSession(
        checkpoint_dir=FLAGS.train_dir,
        hooks=[tf.train.StopAtStepHook(last_step=FLAGS.max_steps),
               tf.train.NanTensorHook(loss), ## Monitors loss and stops training if loss is NaN.
               _LoggerHook()],
        config=tf.ConfigProto(
            log_device_placement=FLAGS.log_device_placement)) as mon_sess:

		##init = tf.global_variables_initializer()
		##sess.run(init)

      		while not mon_sess.should_stop():
			print "in progress %d " % (batch_counter)
        		mon_sess.run(train_op)
			batch_counter = batch_counter + 1



	
##############
def main(argv=None):  
	train()
	
	

if __name__ == '__main__':
  	tf.app.run()

